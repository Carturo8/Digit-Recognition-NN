# ğŸ§  Reconocimiento de DÃ­gitos con Redes Neuronales

Este proyecto es un ejemplo prÃ¡ctico de clasificaciÃ³n supervisada en Python, en el cual se implementa una red neuronal bÃ¡sica del tipo Multilayer Perceptron (MLP) utilizando TensorFlow y Keras para reconocer imÃ¡genes de dÃ­gitos escritos a mano (del 0 al 9), usando el dataset MNIST.

A lo largo del proyecto se muestra cÃ³mo:
- Cargar y preprocesar datos de imagen.
- Construir una red neuronal con Keras.
- Entrenar y validar el modelo.
- Evaluar su desempeÃ±o.
- Realizar predicciones y visualizar resultados.

---

## ğŸ“¦ Paso 1: ImportaciÃ³n de LibrerÃ­as

En este paso se importan las librerÃ­as necesarias para llevar a cabo el proyecto:

```python
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
```

#### ğŸ” Â¿Por quÃ© se usan estas librerÃ­as?

1. `tensorflow`

TensorFlow es una de las bibliotecas mÃ¡s populares para desarrollar y entrenar modelos de machine learning y deep learning. Es mantenida por Google y se usa ampliamente en la industria y en la academia.

En este proyecto usamos Keras, que es una API de alto nivel integrada dentro de TensorFlow (`tensorflow.keras`), diseÃ±ada para facilitar la construcciÃ³n y entrenamiento de redes neuronales.

2. `from tensorflow.keras import layers, models`

Esta lÃ­nea importa mÃ³dulos especÃ­ficos de Keras que nos permiten construir una red neuronal de manera sencilla.

`layers`: contiene las distintas capas que usaremos para construir la red (por ejemplo: Dense, Flatten, etc.).

`models`: nos permite crear modelos del tipo secuencial, que es el mÃ¡s simple (una pila lineal de capas).

3. `matplotlib.pyplot`

Esta biblioteca se usa para visualizar imÃ¡genes o grÃ¡ficas. Es muy Ãºtil para mostrar ejemplos de imÃ¡genes del dataset MNIST, asÃ­ como resultados de predicciÃ³n del modelo.

## ğŸ“¥ Paso 2: Carga del Dataset MNIST

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
```

#### ğŸ” Â¿QuÃ© es MNIST?

MNIST (Modified National Institute of Standards and Technology) es un dataset muy utilizado en tareas de clasificaciÃ³n de imÃ¡genes. Contiene 70.000 imÃ¡genes en escala de grises de dÃ­gitos escritos a mano (del 0 al 9). Cada imagen tiene un tamaÃ±o de 28x28 pÃ­xeles.

Estas imÃ¡genes vienen acompaÃ±adas de sus respectivas etiquetas (labels), que indican quÃ© nÃºmero representa cada imagen.

#### ğŸ“Œ DivisiÃ³n de datos: Â¿QuÃ© son `x_train`, `y_train`, `x_test`, `y_test`?

Cuando trabajamos con aprendizaje supervisado, es fundamental dividir los datos en al menos dos conjuntos principales:

| Variable   | Contenido                                     | PropÃ³sito                        |
|------------|-----------------------------------------------|----------------------------------|
| `x_train`  | ImÃ¡genes de entrenamiento                     | Para entrenar el modelo          |
| `y_train`  | Etiquetas reales (0â€“9) de esas imÃ¡genes       | Para que el modelo aprenda       |
| `x_test`   | ImÃ¡genes no vistas durante el entrenamiento   | Para evaluar el modelo           |
| `y_test`   | Etiquetas reales de las imÃ¡genes de prueba    | Para comparar con predicciones   |

#### ğŸ¯ Â¿Por quÃ© se hace esta separaciÃ³n?

- El modelo aprende a asociar las imÃ¡genes (`x_train`) con sus etiquetas (`y_train`) durante el entrenamiento.

- DespuÃ©s, se evalÃºa su desempeÃ±o usando `x_test` y `y_test`, que contienen datos que el modelo nunca ha visto. AsÃ­ se puede medir si generaliza bien o solo memorizÃ³ los datos.

#### ğŸ§ª Â¿Y quÃ© pasa con la validaciÃ³n?

Durante el entrenamiento tambiÃ©n es importante observar cÃ³mo se comporta el modelo con datos que no estÃ¡ usando directamente para aprender. Para eso existe el conjunto de validaciÃ³n, que sirve para:

- Ajustar los parÃ¡metros del modelo (como el nÃºmero de Ã©pocas, arquitectura, etc.).

- Detectar problemas como sobreajuste (overfitting).

En este proyecto, la validaciÃ³n se implementa mÃ¡s adelante en el cÃ³digo mediante un parÃ¡metro llamado `validation_split`, que permite reservar automÃ¡ticamente una parte del conjunto de entrenamiento con este propÃ³sito. Esto se explicarÃ¡ en detalle mÃ¡s adelante.

## âš™ï¸ Paso 3: NormalizaciÃ³n de las ImÃ¡genes

```python
x_train = x_train / 255.0
x_test = x_test / 255.0
```

#### ğŸ¯ Â¿QuÃ© es la normalizaciÃ³n?

La normalizaciÃ³n es el proceso de escalar los valores de los datos para que estÃ©n dentro de un cierto rango, en este caso entre 0.0 y 1.0.

Cada imagen del dataset MNIST estÃ¡ compuesta por pÃ­xeles con valores enteros entre 0 y 255 (porque es una imagen en escala de grises). Para que la red neuronal pueda entrenarse de forma mÃ¡s eficiente, se normalizan dividiendo cada valor de pÃ­xel entre 255.0.

#### âœ… Â¿Por quÃ© es importante?

- Las redes neuronales trabajan mejor cuando los datos de entrada tienen un rango uniforme y pequeÃ±o.

- Mejora la velocidad de entrenamiento y la estabilidad numÃ©rica.

- Ayuda a que las funciones de activaciÃ³n (como ReLU o sigmoid) funcionen correctamente.

Nota: Esta normalizaciÃ³n solo afecta los datos de entrada (`x_train`, `x_test`), no las etiquetas (`y_train`, `y_test`), ya que estas son categorÃ­as del 0 al 9.

## ğŸ—ï¸ Paso 4: CreaciÃ³n del Modelo de Red Neuronal

```python
model = models.Sequential([
    layers.Flatten(input_shape=(28, 28)),     # Convierte 28x28 pÃ­xeles en un vector de 784
    layers.Dense(128, activation='relu'),     # Capa oculta con 128 neuronas y ReLU
    layers.Dense(10, activation='softmax')    # Capa de salida con 10 clases (0-9)
])
```

#### ğŸ§  Â¿QuÃ© tipo de modelo se estÃ¡ creando?

Se construye una red neuronal secuencial, lo que significa que las capas estÃ¡n conectadas una tras otra en orden.

#### ğŸ” ExplicaciÃ³n de cada capa:

| Capa                             | FunciÃ³n                                                                                                                                                     |
|----------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `Flatten(input_shape=(28, 28))`  | Convierte la imagen 2D (28x28 pÃ­xeles) en un vector de 784 valores. Esto es necesario para que los datos puedan ser procesados por las capas densas.       |
| `Dense(128, activation='relu')` | Crea una capa oculta con 128 neuronas. Se usa la funciÃ³n de activaciÃ³n ReLU (Rectified Linear Unit), que introduce no linealidad y ayuda a aprender patrones. |
| `Dense(10, activation='softmax')`| Capa de salida con 10 neuronas, una para cada dÃ­gito (0 al 9). La funciÃ³n softmax transforma los valores en probabilidades para cada clase.                  |

#### ğŸ¯ Â¿Por quÃ© esta arquitectura?

- Es una red sencilla pero efectiva para un problema como MNIST.

- Usar una sola capa oculta con 128 neuronas es suficiente para lograr una precisiÃ³n razonable.

- Se prioriza la claridad y la didÃ¡ctica sobre el rendimiento avanzado, ya que el enfoque es de aprendizaje.

MÃ¡s adelante se podrÃ¡ experimentar agregando mÃ¡s capas, cambiando el nÃºmero de neuronas o usando otras funciones de activaciÃ³n para ver cÃ³mo afecta al rendimiento.

## âš™ï¸ Paso 5: Compilar el Modelo

```python
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

#### ğŸ§ª Â¿QuÃ© significa compilar un modelo?

Antes de entrenar una red neuronal, es necesario compilarla, lo que implica definir tres aspectos clave:

| ParÃ¡metro                         | DescripciÃ³n                                                                                                                                                               |
|----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `optimizer='adam'`               | El optimizador determina cÃ³mo se actualizan los pesos durante el entrenamiento. Adam es un algoritmo muy eficiente y popular que ajusta automÃ¡ticamente la tasa de aprendizaje. |
| `loss='sparse_categorical_crossentropy'` | La funciÃ³n de pÃ©rdida mide quÃ© tan mal estÃ¡ prediciendo el modelo. En este caso, como las etiquetas son enteros del 0 al 9 (y no one-hot), se usa `sparse_categorical_crossentropy`. |
| `metrics=['accuracy']`           | Se evalÃºa el desempeÃ±o del modelo utilizando la precisiÃ³n (`accuracy`), es decir, el porcentaje de predicciones correctas.                                                |

## ğŸš€ Paso 6: Entrenar el Modelo

```python
model.fit(x_train, y_train, epochs=5, validation_split=0.1)
```

#### ğŸ§  Â¿QuÃ© hace fit()?

La funciÃ³n `fit()` entrena el modelo utilizando los datos de entrada (`x_train`) y sus etiquetas reales (`y_train`) durante un nÃºmero determinado de Ã©pocas (iteraciones completas sobre los datos).

#### ğŸ“Œ Detalles del entrenamiento:

| ParÃ¡metro               | Significado                                                                                                                                   |
|-------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| `x_train`, `y_train`    | Datos con los que el modelo va a aprender.                                                                                                   |
| `epochs=5`              | El modelo revisa todos los datos 5 veces para mejorar su desempeÃ±o.                                                                          |
| `validation_split=0.1`  | El 10% del conjunto de entrenamiento se reserva para validaciÃ³n, lo cual permite monitorear si el modelo generaliza bien o se estÃ¡ sobreajustando (*overfitting*). |

La validaciÃ³n no afecta el entrenamiento directamente, pero ayuda a verificar el progreso del modelo con datos que no estÃ¡ usando para aprender, evitando asÃ­ errores por sobreajuste.

## ğŸ§ª Paso 7: Evaluar el Modelo con el Conjunto de Prueba

```python
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'\nPrecisiÃ³n del modelo en datos de prueba: {test_acc:.4f}')
```

#### ğŸ¯ Â¿QuÃ© hace `evaluate()`?

La funciÃ³n `evaluate()` permite medir el rendimiento final del modelo usando datos que nunca se usaron en el entrenamiento ni en la validaciÃ³n. Esto proporciona una estimaciÃ³n realista de cÃ³mo funcionarÃ¡ el modelo con datos nuevos.

#### ğŸ“Œ Detalles de la evaluaciÃ³n:

| Comando                        | Significado                                                                                                                     |
|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------|
| `model.evaluate(x_test, y_test)` | EvalÃºa el modelo con imÃ¡genes de prueba y devuelve dos valores: la **pÃ©rdida** (`loss`) y la **precisiÃ³n** (`accuracy`).       |
| `test_loss`                   | Indica quÃ© tan mal se desempeÃ±Ã³ el modelo en tÃ©rminos de pÃ©rdida.                                                               |
| `test_acc`                    | Muestra la precisiÃ³n obtenida en el conjunto de prueba (porcentaje de clasificaciones correctas).                               |

Esta etapa es fundamental para entender si el modelo realmente aprendiÃ³ o simplemente memorizÃ³ los datos de entrenamiento. Una alta precisiÃ³n en prueba sugiere que el modelo generaliza bien.

#### ğŸ§¾ Resultado obtenido:

```python
PrecisiÃ³n del modelo en datos de prueba: 0.9766
```

#### ğŸ“ˆ Â¿QuÃ© significa ese valor?

Una precisiÃ³n de 0.9766 (o 97.66%) indica que el modelo acertÃ³ en casi el 98% de los casos al clasificar dÃ­gitos escritos a mano que nunca habÃ­a visto antes.

âœ… Esto sugiere que el modelo generaliza muy bien y es bastante confiable para este tipo de tarea.

## ğŸ” Paso 8: Hacer Predicciones y Visualizar Resultados

```python
predictions = model.predict(x_test)

# Mostrar 5 ejemplos de predicciÃ³n
for i in range(5):
    plt.imshow(x_test[i], cmap='gray')
    plt.title(f'PredicciÃ³n: {predictions[i].argmax()}, Etiqueta real: {y_test[i]}')
    plt.axis('off')
    plt.show()
```

#### ğŸ§  Â¿QuÃ© hace este bloque de cÃ³digo?

- Se generan predicciones con el modelo ya entrenado usando el conjunto de prueba (`x_test`).

- Se muestran las primeras 5 imÃ¡genes junto con:

  - La predicciÃ³n del modelo (`predictions[i].argmax()`)

  - La etiqueta real (`y_test[i]`)

- Esto permite ver visualmente cÃ³mo estÃ¡ funcionando el modelo.

#### Ejemplos de predicciones del modelo

![img1](images/predict_0.png)
![img2](images/predict_1.png)
![img3](images/predict_2.png)
![img4](images/predict_3.png)
![img5](images/predict_4.png)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - consulta el archivo [LICENSE](https://github.com/Carturo8/Digit-Recognition-NN/blob/main/LICENSE) para mÃ¡s detalles.
